{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "/**\n",
        " * Tensorflow.js Examples for Node.js\n",
        " * Script adatapted from \n",
        " * https://github.com/tensorflow/tfjs-examples\n",
        " * https://groups.google.com/a/tensorflow.org/forum/#!forum/tfjs\n",
        " * @author Loreto Parisi (loretoparisi@gmail.com)\n",
        " * @copyright 2018 Loreto Parisi (loretoparisi@gmail.com)\n",
        " */\n",
        "const tf = require('@tensorflow/tfjs');\n",
        "require('@tensorflow/tfjs-node');\n",
        "\n",
        "var fs = require('fs');\n",
        "var performance = require('perf_hooks').performance;"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": [
              "{ version: '0.1.9' }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(node:19644) Warning: N-API is an experimental feature and could change at any time.\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "//\n",
        "// Script adapted from: https://codepen.io/caisq/pen/vrxOvy\n",
        "//\n",
        "// TensorFlow.js example: Trains LSTM model to perform the following sequence task:\n",
        "//\n",
        "// Given a sequence of 0s and 1s of fixed length (10), output a single binary number (0 or 1).\n",
        "//\n",
        "// The training data has the following pattern:\n",
        "//\n",
        "// The output (i.e., label) is 1 if there are four or more consecutive and identical\n",
        "// items (either 0s or 1s) in the input sequence. Otherwise, the output is 0. For example:\n",
        "//   Sequence [0, 1, 0, 1, 0, 1, 0, 0, 1, 0] --> Label: 0.\n",
        "//   Sequence [0, 1, 1, 1, 1, 0, 1, 0, 0, 1] --> Label: 1.\n",
        "//   Sequence [0, 0, 0, 0, 0, 0, 1, 0, 0, 1] --> Label: 1.\n",
        "\n",
        "const sequenceLength = 10;\n",
        "const stretchLengthThreshold = 4;\n",
        "\n",
        "// Generates sequences consisting of 0 and 1 and the associated 0-1 labels.\n",
        "//  \n",
        "// The sequences and labels follow the pattern described above.\n",
        "//\n",
        "// Args:\n",
        "//   len: Length of the sequence.\n",
        "// \n",
        "// Returns:\n",
        "//   1. An Array of randomly-generated 0s and 1s.\n",
        "//   2. The associated output (label): a 0 or a 1.\n",
        "function generateSequenceAndLabel(len) {\n",
        "    const sequence = [];\n",
        "    let currentItem = -1;\n",
        "    let stretchLength = 0;\n",
        "    let label = 0;\n",
        "    for (let i = 0; i < len; ++i) {\n",
        "        const item = Math.random() > 0.5 ? 1 : 0;\n",
        "        sequence.push(item);\n",
        "        if (currentItem === item) {\n",
        "            stretchLength++;\n",
        "        } else {\n",
        "            currentItem = item;\n",
        "            stretchLength = 1;\n",
        "        }\n",
        "        if (stretchLength >= stretchLengthThreshold) {\n",
        "            label = 1;\n",
        "        }\n",
        "    }\n",
        "    return [sequence, label];\n",
        "}"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "// Generates sequences consisting of 0 and 1 and the associated 0-1 labels.\n",
        "//  \n",
        "// The sequences and labels follow the pattern described above.\n",
        "//\n",
        "// Args:\n",
        "//   len: Length of the sequence.\n",
        "// \n",
        "// Returns:\n",
        "//   1. An Array of randomly-generated 0s and 1s.\n",
        "//   2. The associated output (label): a 0 or a 1.\n",
        "function generateSequenceAndLabel(len) {\n",
        "    const sequence = [];\n",
        "    let currentItem = -1;\n",
        "    let stretchLength = 0;\n",
        "    let label = 0;\n",
        "    for (let i = 0; i < len; ++i) {\n",
        "        const item = Math.random() > 0.5 ? 1 : 0;\n",
        "        sequence.push(item);\n",
        "        if (currentItem === item) {\n",
        "            stretchLength++;\n",
        "        } else {\n",
        "            currentItem = item;\n",
        "            stretchLength = 1;\n",
        "        }\n",
        "        if (stretchLength >= stretchLengthThreshold) {\n",
        "            label = 1;\n",
        "        }\n",
        "    }\n",
        "    return [sequence, label];\n",
        "}// Generates a dataset consisting of sequences and their corresponding labels.\n",
        "//\n",
        "// Args:\n",
        "//   numExamples: Number of examples to generate.\n",
        "//   sequenceLength: Length of each individual sequence.\n",
        "//\n",
        "// Returns:\n",
        "//   1. Sequence Tensor: a Tensor of shape [numExamples, sequenceLength, 2].\n",
        "//      The first dimension is the batch examples.\n",
        "//      The second dimension is the time axis (sequence items).\n",
        "//      The third dimension is the one-hot encoding of the 0/1 items.\n",
        "//   2. Label Tensor: a Tensor of shape [numExamples, 1].\n",
        "//      Each element of this Tensor is 0 or 1. \n",
        "function generateDataset(numExamples, sequenceLength) {\n",
        "    const sequencesBuffer = tf.buffer([numExamples, sequenceLength, 2]);\n",
        "    const labelsBuffer = tf.buffer([numExamples, 1]);\n",
        "    for (let i = 0; i < numExamples; ++i) {\n",
        "        const [sequence, label] = generateSequenceAndLabel(sequenceLength);\n",
        "        for (let j = 0; j < sequenceLength; ++j) {\n",
        "            sequencesBuffer.set(1, i, j, sequence[j]);\n",
        "        }\n",
        "        labelsBuffer.set(label, i, 0);\n",
        "    }\n",
        "    return [sequencesBuffer.toTensor(), labelsBuffer.toTensor()];\n",
        "}\n",
        "\n",
        "tf.nextFrame = function () {\n",
        "    return new Promise((resolve, reject) => {\n",
        "        process.nextTick(function () {\n",
        "            return resolve(true);\n",
        "        });\n",
        "    });\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": [
              "[Function]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "// Train a model to predict the label based on the sequence.\n",
        "function train() {\n",
        "    return new Promise((resolve, reject) => {\n",
        "        // Define the topology of the model.\n",
        "        const model = tf.sequential();\n",
        "        model.add(tf.layers.lstm({ units: 8, inputShape: [sequenceLength, 2] }));\n",
        "        model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));\n",
        "\n",
        "        // Compile model to prepare for training.\n",
        "        const learningRate = 4e-3;\n",
        "        const optimizer = tf.train.rmsprop(learningRate);\n",
        "        model.compile({\n",
        "            loss: 'binaryCrossentropy',\n",
        "            optimizer: optimizer,\n",
        "            metrics: ['acc']\n",
        "        });\n",
        "\n",
        "        // Generate a number of examples for training.\n",
        "        const numTrainExamples = 500;\n",
        "        console.log('Generating training data...');\n",
        "        const [trainSequences, trainLabels] = generateDataset(numTrainExamples, 10);\n",
        "\n",
        "        let status = {\n",
        "            train_epoch: 0,\n",
        "            train_loss: 0,\n",
        "            train_acc: 0,\n",
        "            val_loss: 0,\n",
        "            val_acc: 0\n",
        "        };\n",
        "        console.log('Training model...');\n",
        "        model.fit(\n",
        "            trainSequences, trainLabels, {\n",
        "                epochs: 5,\n",
        "                validationSplit: 0.15,\n",
        "                callbacks: {\n",
        "                    onBatchEnd: (batch, logs) => {\n",
        "                        console.log(batch,logs);\n",
        "                        tf.nextFrame().then(res => {\n",
        "                            return;\n",
        "                        })\n",
        "                    },\n",
        "                    onEpochEnd: (epoch, logs) => {\n",
        "                        // Update the UI to display the current loss and accuracy values.\n",
        "                        status.train_epoch = epoch + 1;\n",
        "                        status.train_loss = logs.loss;\n",
        "                        status.train_acc = logs.acc;\n",
        "                        status.val_loss = logs.val_loss;\n",
        "                        status.val_acc = logs.val_acc;\n",
        "                        console.log(status);\n",
        "                        tf.nextFrame().then(res => {\n",
        "                            return;\n",
        "                        })\n",
        "                    },\n",
        "                }\n",
        "            }).then(fitOutput => {\n",
        "                // Memory clean up: Dispose the training data.\n",
        "                trainSequences.dispose();\n",
        "                trainLabels.dispose();\n",
        "                return resolve(fitOutput);\n",
        "            })\n",
        "            .catch(error => {\n",
        "                return reject(error);\n",
        "            })\n",
        "    })\n",
        "}"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train()\n",
        "    .then(res => {\n",
        "        console.log(res);\n",
        "    })\n",
        "    .catch(error => {\n",
        "        console.error(error);\n",
        "    })"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training data...\n",
            "Training model...\n",
            "0 { batch: 0, size: 32, loss: 0.6925153732299805, acc: 0.40625 }\n",
            "1 { batch: 1, size: 32, loss: 0.6889982223510742, acc: 0.78125 }\n",
            "2 { batch: 2, size: 32, loss: 0.6903518438339233, acc: 0.53125 }\n",
            "3 { batch: 3, size: 32, loss: 0.6850794553756714, acc: 0.59375 }\n",
            "4 { batch: 4, size: 32, loss: 0.6909929513931274, acc: 0.53125 }\n",
            "5 { batch: 5, size: 32, loss: 0.6916240453720093, acc: 0.5 }\n",
            "6 { batch: 6, size: 32, loss: 0.6963074207305908, acc: 0.46875 }\n",
            "7 { batch: 7, size: 32, loss: 0.6866735219955444, acc: 0.59375 }\n",
            "8 { batch: 8, size: 32, loss: 0.7017056941986084, acc: 0.4375 }\n",
            "9 { batch: 9, size: 32, loss: 0.6944520473480225, acc: 0.46875 }\n",
            "10 { batch: 10, size: 32, loss: 0.6854808330535889, acc: 0.5625 }\n",
            "11 { batch: 11, size: 32, loss: 0.689024806022644, acc: 0.5625 }\n",
            "12 { batch: 12, size: 32, loss: 0.682608425617218, acc: 0.59375 }\n",
            "13 { batch: 13,\n",
            "  size: 9,\n",
            "  loss: 0.700183629989624,\n",
            "  acc: 0.4444444477558136 }\n",
            "{ train_epoch: 1,\n",
            "  train_loss: 0.6906535625457764,\n",
            "  train_acc: 0.5388234853744507,\n",
            "  val_loss: 0.690714418888092,\n",
            "  val_acc: 0.5333333611488342 }\n",
            "0 { batch: 0, size: 32, loss: 0.6942626237869263, acc: 0.5 }\n",
            "1 { batch: 1, size: 32, loss: 0.6854543685913086, acc: 0.5625 }\n",
            "2 { batch: 2, size: 32, loss: 0.6871836185455322, acc: 0.53125 }\n",
            "3 { batch: 3, size: 32, loss: 0.7004063129425049, acc: 0.4375 }\n",
            "4 { batch: 4, size: 32, loss: 0.6847056746482849, acc: 0.5625 }\n",
            "5 { batch: 5, size: 32, loss: 0.6849592924118042, acc: 0.59375 }\n",
            "6 { batch: 6, size: 32, loss: 0.6904247999191284, acc: 0.53125 }\n",
            "7 { batch: 7, size: 32, loss: 0.6930062770843506, acc: 0.5 }\n",
            "8 { batch: 8, size: 32, loss: 0.6806856393814087, acc: 0.625 }\n",
            "9 { batch: 9, size: 32, loss: 0.6783318519592285, acc: 0.625 }\n",
            "10 { batch: 10, size: 32, loss: 0.6943924427032471, acc: 0.5 }\n",
            "11 { batch: 11, size: 32, loss: 0.6635617613792419, acc: 0.6875 }\n",
            "12 { batch: 12, size: 32, loss: 0.7046899795532227, acc: 0.46875 }\n",
            "13 { batch: 13,\n",
            "  size: 9,\n",
            "  loss: 0.726859450340271,\n",
            "  acc: 0.3333333432674408 }\n",
            "{ train_epoch: 2,\n",
            "  train_loss: 0.6886771321296692,\n",
            "  train_acc: 0.5435293912887573,\n",
            "  val_loss: 0.6904875040054321,\n",
            "  val_acc: 0.5333333611488342 }\n",
            "0 { batch: 0, size: 32, loss: 0.6987434029579163, acc: 0.4375 }\n",
            "1 { batch: 1, size: 32, loss: 0.676891565322876, acc: 0.65625 }\n",
            "2 { batch: 2, size: 32, loss: 0.6803567409515381, acc: 0.59375 }\n",
            "3 { batch: 3, size: 32, loss: 0.6897504925727844, acc: 0.53125 }\n",
            "4 { batch: 4, size: 32, loss: 0.6977275609970093, acc: 0.46875 }\n",
            "5 { batch: 5, size: 32, loss: 0.6819972395896912, acc: 0.5625 }\n",
            "6 { batch: 6, size: 32, loss: 0.698636531829834, acc: 0.46875 }\n",
            "7 { batch: 7, size: 32, loss: 0.6713629961013794, acc: 0.65625 }\n",
            "8 { batch: 8, size: 32, loss: 0.7096338868141174, acc: 0.40625 }\n",
            "9 { batch: 9, size: 32, loss: 0.6928606033325195, acc: 0.53125 }\n",
            "10 { batch: 10, size: 32, loss: 0.7108947038650513, acc: 0.40625 }\n",
            "11 { batch: 11, size: 32, loss: 0.6755589842796326, acc: 0.6875 }\n",
            "12 { batch: 12, size: 32, loss: 0.6738412380218506, acc: 0.625 }\n",
            "13 { batch: 13,\n",
            "  size: 9,\n",
            "  loss: 0.6705348491668701,\n",
            "  acc: 0.6666666865348816 }\n",
            "{ train_epoch: 3,\n",
            "  train_loss: 0.6887035369873047,\n",
            "  train_acc: 0.5435293912887573,\n",
            "  val_loss: 0.6906557679176331,\n",
            "  val_acc: 0.5333333611488342 }\n",
            "0 { batch: 0, size: 32, loss: 0.6938928961753845, acc: 0.5 }\n",
            "1 { batch: 1, size: 32, loss: 0.695366621017456, acc: 0.5 }\n",
            "2 { batch: 2, size: 32, loss: 0.6760042905807495, acc: 0.59375 }\n",
            "3 { batch: 3, size: 32, loss: 0.6844825744628906, acc: 0.5625 }\n",
            "4 { batch: 4, size: 32, loss: 0.6820464730262756, acc: 0.5625 }\n",
            "5 { batch: 5, size: 32, loss: 0.6946588754653931, acc: 0.5 }\n",
            "6 { batch: 6, size: 32, loss: 0.6848519444465637, acc: 0.5625 }\n",
            "7 { batch: 7, size: 32, loss: 0.7038799524307251, acc: 0.46875 }\n",
            "8 { batch: 8, size: 32, loss: 0.6885184049606323, acc: 0.53125 }\n",
            "9 { batch: 9, size: 32, loss: 0.6809780597686768, acc: 0.59375 }\n",
            "10 { batch: 10, size: 32, loss: 0.6705784797668457, acc: 0.625 }\n",
            "11 { batch: 11, size: 32, loss: 0.705894947052002, acc: 0.46875 }\n",
            "12 { batch: 12, size: 32, loss: 0.6804052591323853, acc: 0.59375 }\n",
            "13 { batch: 13,\n",
            "  size: 9,\n",
            "  loss: 0.679257869720459,\n",
            "  acc: 0.5555555820465088 }\n",
            "{ train_epoch: 4,\n",
            "  train_loss: 0.6876310110092163,\n",
            "  train_acc: 0.5435293912887573,\n",
            "  val_loss: 0.690804123878479,\n",
            "  val_acc: 0.5333333611488342 }\n",
            "0 { batch: 0, size: 32, loss: 0.6962457299232483, acc: 0.5 }\n",
            "1 { batch: 1, size: 32, loss: 0.6888812184333801, acc: 0.53125 }\n",
            "2 { batch: 2, size: 32, loss: 0.6413850784301758, acc: 0.8125 }\n",
            "3 { batch: 3, size: 32, loss: 0.6825156807899475, acc: 0.5625 }\n",
            "4 { batch: 4, size: 32, loss: 0.6757480502128601, acc: 0.59375 }\n",
            "5 { batch: 5, size: 32, loss: 0.689529538154602, acc: 0.53125 }\n",
            "6 { batch: 6, size: 32, loss: 0.7015009522438049, acc: 0.5 }\n",
            "7 { batch: 7, size: 32, loss: 0.702332615852356, acc: 0.5 }\n",
            "8 { batch: 8, size: 32, loss: 0.7147812247276306, acc: 0.40625 }\n",
            "9 { batch: 9, size: 32, loss: 0.6896429061889648, acc: 0.5 }\n",
            "10 { batch: 10, size: 32, loss: 0.6593785285949707, acc: 0.71875 }\n",
            "11 { batch: 11, size: 32, loss: 0.7109782695770264, acc: 0.40625 }\n",
            "12 { batch: 12, size: 32, loss: 0.7025759220123291, acc: 0.46875 }\n",
            "13 { batch: 13,\n",
            "  size: 9,\n",
            "  loss: 0.65365070104599,\n",
            "  acc: 0.6666666865348816 }\n",
            "{ train_epoch: 5,\n",
            "  train_loss: 0.6881381273269653,\n",
            "  train_acc: 0.5435293912887573,\n",
            "  val_loss: 0.6907000541687012,\n",
            "  val_acc: 0.5333333611488342 }\n",
            "History {\n",
            "  validationData: null,\n",
            "  params: \n",
            "   { epochs: 5,\n",
            "     steps: null,\n",
            "     verbose: undefined,\n",
            "     doValidation: true,\n",
            "     metrics: [ 'loss', 'acc', 'val_loss', 'val_acc' ] },\n",
            "  epoch: [ 0, 1, 2, 3, 4 ],\n",
            "  history: \n",
            "   { val_loss: \n",
            "      [ 0.690714418888092,\n",
            "        0.6904875040054321,\n",
            "        0.6906557679176331,\n",
            "        0.690804123878479,\n",
            "        0.6907000541687012 ],\n",
            "     val_acc: \n",
            "      [ 0.5333333611488342,\n",
            "        0.5333333611488342,\n",
            "        0.5333333611488342,\n",
            "        0.5333333611488342,\n",
            "        0.5333333611488342 ],\n",
            "     loss: \n",
            "      [ 0.6906535625457764,\n",
            "        0.6886771321296692,\n",
            "        0.6887035369873047,\n",
            "        0.6876310110092163,\n",
            "        0.6881381273269653 ],\n",
            "     acc: \n",
            "      [ 0.5388234853744507,\n",
            "        0.5435293912887573,\n",
            "        0.5435293912887573,\n",
            "        0.5435293912887573,\n",
            "        0.5435293912887573 ] } }\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "node_nteract"
    },
    "language_info": {
      "name": "javascript",
      "version": "8.9.3",
      "mimetype": "application/javascript",
      "file_extension": ".js"
    },
    "kernelspec": {
      "name": "node_nteract",
      "language": "javascript",
      "display_name": "Node.js (nteract)"
    },
    "nteract": {
      "version": "0.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}